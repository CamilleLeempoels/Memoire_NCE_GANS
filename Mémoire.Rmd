---
title: "Noise-contrastive estimation of normalising constants and GANs"
header-includes:
  - \usepackage{mathrsfs}
  - \usepackage{bm}
  - \usepackage{dsfont}
  - \usepackage{amsmath}
  - \usepackage{mdframed}
  - \usepackage{placeins}
output: pdf_document
fig_width: 3
fig_height: 2
---


\section{Fonctions génériques}

\subsection{Algorithme d'Hasting}

Utilité : simuler selon $p_m(.,\psi)$ pour un paramètre $\psi$ choisi. 

\begin{table}[!h]
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Argument} & \textbf{Type} & \textbf{Exemple} & \textbf{Indication} \\ \hline
x & vecteur & rcauchy(100, 0, 1) &  notre échantillon de densité inconnue \\ \hline
n & entier & 100 & taille de la simulation \\ \hline
psi & vecteur & c(0,1) & paramètres de la fonction h \\ \hline
h & fonction &  & fonction qui retourne $\overline{p_m}(.,\psi)$\\ \hline
\end{tabular}
\end{table}

```{r}
hasting = function(x, n, psi, h){
  y = c()
  y = append(y, sample(sample(x, 1)))
  for (i in 2:n){
    y_ = rnorm(1, y[i-1], 1)
    u = runif(1)
    if ( u <= 
         (h(y_,psi) * dnorm(y_, y[i-1], 1))
         /(h(y[i-1],psi) * dnorm(y[i-1], y_, 1))
    ){ 
      y = append(y, y_)} 
    else { 
      y = append(y, y[i-1])
    }
  }
  return (y)
}
```


Note : on peut très certainement écrire sous forme matricielle cette fonction pour une meilleure performance.

\subsection{MC MLE}

Utilité : retourne une estimation des paramètres selon la méthode décrite dans le papier de Geyer. 

```{r}
mc_mle = function(x, n, psi, h){

  y = hasting(x, n, psi, h)
    
  L = function(theta){
    return(sum(log(h(x,theta)/h(x,psi))) - n*log(mean(h(y,theta)/h(y,psi))))
  }
  
  theta = optim(
    par = rep(1,length(psi)),
    gr = "CG",
    control = list(fnscale=-1),
    fn = L
  )$par

  return(theta)
}
```


\subsection{NCE}

Utilité : Retourne l'estimation de la constante et des paramètres.

\begin{table}[!h]
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Argument} & \textbf{Type} & \textbf{Exemple} & \textbf{Indication} \\ \hline
x & vecteur & rcauchy(100, 0, 1) & notre échantillon de densité inconnue \\ \hline
law\_y & fonction & rnorm & fonction qui retourne un échantillon suivant la loi $p_n$ \\ \hline
n & entier & 100 & taille de l'échantillon de bruit suivant la loi $p_n$ \\ \hline
params\_y & vecteur & c(0,1) & arguments de la fonction law\_y \\ \hline
log\_pm & fonction &  & fonction qui retourne le logarithme de la densité $p_m$ \\ \hline
log\_pn & fonction &  & fonction qui retourne le logarithme de la densité $p_n$ \\ \hline
size\_theta & entier & 3 & taille de $\theta$, vaut habituellement 2 ou 3 \\ \hline
method & string & "CG" & méthode d'optimisation, habituellement "CG" ou "BFGS" \\ \hline
\end{tabular}
\end{table}

```{r}
nce = function(x, law_y, n, params_y, log_pm, log_pn, size_theta, methode = "CG"){
  
  y = do.call(law_y,c(list(n),params_y))
  
  m = length(x)
  
  h = function(u, theta){
    return( 1 / (1 + n/m * exp(log_pn(u) - log_pm(u, theta))))
  }
  
  J = function(theta){
    return( sum(log(h(x, theta))) + sum(log(1 - h(y, theta))) )
  }
  
  theta = optim(
    par = rep(1, size_theta),
    gr = methode,
    control = list(fnscale=-1),
    fn = J
  )$par
  
  return(c(theta[-1], exp(-theta[1])))
}
```

\subsection{Graphiques}

```{r}
library(ggplot2)
```

Utilité : afficher l'histogramme pour un échantillon de données $x$.

```{r}
print_hist = function(x) {
  
  df = data.frame(x = x)
  
  hist_x = ggplot(df, aes(x=x)) + geom_histogram(aes(y = stat(count) / sum(count)), bins = 20, color="white") + theme(aspect.ratio = 1) + labs(y = "Fréquence") + ggtitle("Distribution de l'échantillon x")
  
  print(hist_x)
}
```


```{r}

```


\section{Exemple basique : la loi normale}

Soit $x$ l'échantillon de taille $m$ obtenu selon la loi de densité inconnue $p_d$.

On considère ici que $p_d$ appartient à la famille de fonctions paramétrées par $\theta = (c, \mu, \sigma)$ suivante :

$$p_m(u;\theta) = \frac{1}{Z(\mu, \sigma)} \times exp \big[-\frac{1}{2} \big(\frac{u - \mu}{\sigma} \big)^2 \big]  \quad \mbox{d'où} \quad ln(p_m(u;\theta)) = c - \frac{1}{2} \big(\frac{u}{\sigma} - \frac{\mu}{\sigma} \big)^2$$

```{r}
log_pm = function(u,theta){
  return(theta[1] - 1/2 * (u/theta[3] - theta[2]/theta[3]) ** 2)
  # theta[1] = c / theta[2] = mu / theta[3] = sigma
}

log_pn_cauchy = function(u){
  return(log(dcauchy(u, mean(x), sd(x))))
}

m = 1000
n = 10000
x = rnorm(m, 2, 4)
size_theta = 3

nce(x, rcauchy, n, c(mean(x),sd(x)), log_pm, log_pn_cauchy, size_theta)

```
```{r}
print_hist(x)
```


